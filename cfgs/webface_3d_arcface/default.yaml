
# num_classes: 1000
# num_classes: 2000
num_classes: 5000
# num_classes: 10000
# num_classes: 93424

wandb:
  # project: PointNeXt_WEBFACE-3D_1000classes
  # project: PointNeXt_WEBFACE-3D_2000classes
  project: PointNeXt_WEBFACE-3D_5000classes
  # project: PointNeXt_WEBFACE-3D_10000classes
  # project: PointNeXt_WEBFACE-3D_93424classes (whole dataset)

dataset:
  common:
    # NAME: WEBFACE_3D_1000subj   # 1000 CLASSES
    # data_dir: '/nobackup1/bjgbiesseck/datasets/WebFace260M_3D_reconstruction_originalMICA/images_1000subj'
  
    # NAME: WEBFACE_3D_2000subj   # 2000 CLASSES
    # data_dir: '/nobackup1/bjgbiesseck/datasets/WebFace260M_3D_reconstruction_originalMICA/images_2000subj'

    NAME: WEBFACE_3D_5000subj   # 5000 CLASSES
    data_dir: '/nobackup1/bjgbiesseck/datasets/WebFace260M_3D_reconstruction_originalMICA/images_5000subj'

    # NAME: WEBFACE_3D_10000subj  # 10000 CLASSES
    # data_dir: '/nobackup1/bjgbiesseck/datasets/WebFace260M_3D_reconstruction_originalMICA/images_10000subj'

  train:
    split: train
    num_points: 1024  # in training, use sampled 1024 points for data augmentation.
    # num_points: 2048
    # num_points: 2900  # Default value for faces reconstructed by MICA
  val:
    split: test
    num_points: 1024  # in testing, use uniformly pre-sampled 1024 points for evaluation (following https://github.com/lulutang0608/Point-BERT)
    # num_points: 2048
    # num_points: 2900  # Default value for faces reconstructed by MICA

# Dataset Related
num_points: 1024  # number of poins actually used in training and evaluation
# num_points: 2048
# num_points: 2900  # Default value for faces reconstructed by MICA

# Bernardo
# val_other_datasets: null
val_other_datasets: ['lfw']

feature_keys: pos

datatransforms:
  train: [PointsToTensor, PointCloudScaleAndTranslate]  # rotation does not help
  vote: [PointCloudScaleAndTranslate]
  val: [PointsToTensor]
  kwargs:
    shift: [0.2, 0.2, 0.2]
# batch_size: 32     # original
batch_size: 64
# batch_size: 128
# batch_size: 16
# batch_size: 8
dataloader:
  num_workers: 6

# ---------------------------------------------------------------------------- #
# Training cfgs
# ---------------------------------------------------------------------------- #
# training receipe borrowed from: https://github.com/yanx27/Pointnet_Pointnet2_pytorch

# ---------------------------------------------------------------------------- #
# Training cfgs
# ---------------------------------------------------------------------------- #

# Training parameters
# lr: 0.001
# lr: 0.0001
lr: 0.00015
# lr: 0.0005

# this one is better. 
sched: cosine
# epochs: 100
epochs: 100
warmup_epochs: 0
min_lr: null

optimizer:
 # NAME: 'adamw'   # original
 NAME: 'sgd'
 weight_decay: 0.05

grad_norm_clip: 1

criterion_args:   # args passed to openpoints/loss/build.py -> ArcFace.__init__()
  NAME: ArcFace   # for face recognition
  margin: 0.25
  scale: 16

# ---------------------------------------------------------------------------- #
# io and misc
# ---------------------------------------------------------------------------- #
log_dir: 'webface_3d'
print_freq: 10
val_freq: 1

# ----------------- Model related
val_batch_size: 64     # original
# val_batch_size: 128
pretrained_path: null

seed: null
